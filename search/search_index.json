{"config":{"lang":["en"],"separator":"[\\s\\-\\.]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#rajivs-programming-notes","title":"Rajiv's Programming Notes","text":"<p>Hi, I am Rajiv Harlalka, scribbling all my thoughts here. </p> <p>It all starts with an Index and grows on slowly. The first node, the first md file is the motivation needed to start off with doing things.</p> <p>I love to read and talk about things which excite and amaze me, be it about coffee brewing , understanding an interpreter to knowing how a guitar makes sound.</p> <p>Recently I have been following the idea of 5 and would love to talk more incase interested.Can contact me over through: - Twitter: rajivharlalka09 - Linkedin: rajivharlalka - Email: rajivharlalka009@gmail.com</p>"},{"location":"Daily%20Notes/2023-05-25/","title":"2023 05 25","text":"<p>Lot about checkpoint tuning https://www.2ndquadrant.com/en/blog/basics-of-tuning-checkpoints/</p> <ul> <li>Context in postgresql conf tells which parameters will need which type of reload to take effects.</li> <li>![[Pasted image 20230526153642.png]]</li> </ul>"},{"location":"Daily%20Notes/2023-06-05/","title":"2023 06 05","text":""},{"location":"Daily%20Notes/2023-06-05/#multitasking-giving-the-world-an-advantage-it-shouldnt-have","title":"Multitasking: Giving the World an Advantage it Shouldn't Have","text":"<p>URL: https://fs.blog/multitasking-giving-world-advantage/ - I think when you multi-task so much, you don\u2019t have time to think about anything deeply.</p>"},{"location":"Daily%20Notes/2023-06-05/#how-to-make-smart-decisions-without-getting-lucky","title":"How to Make Smart Decisions Without Getting Lucky","text":"<p>URL: https://fs.blog/smart-decisions/</p>"},{"location":"Daily%20Notes/2023-06-05/#httphighscalabilitycomblog2013128duckduckgo-architecture-1-million-deep-searches-a-day-and-grhtml","title":"http://highscalability.com/blog/2013/1/28/duckduckgo-architecture-1-million-deep-searches-a-day-and-gr.html","text":"<ul> <li> <p>CMU Database Group</p> </li> <li> <p>[[How Successful People Increase Productivity]] URL: https://fs.blog/saying-no-how-successful-people-stay-productive/</p> </li> </ul>"},{"location":"KOSS/Self-Hosting%20101/","title":"Workshop","text":""},{"location":"KOSS/Self-Hosting%20101/#what-can-be-proposed-in-the-workshop","title":"What can be proposed in the workshop","text":"<ul> <li>Containerization</li> <li>Forward and reverse Proxy using nginx/Apache.</li> <li>Setting up everything on a small VM (we can provide it).</li> <li>Self Hosting an open source application.</li> </ul>"},{"location":"Languages%26Tools/Rust/","title":"Rust","text":"<ul> <li>It has a special kind of switch statement called match, which does the same think as that of a switch.</li> <li>Vector's in rust are known as collections. They can be iterated over. Anything that can be looped through can be considered as a collection.</li> <li>In Rust assignment(assigning value using =) is considered to be moving values and not copying.</li> <li>To pass data as reference, we need to use the &amp; operator to assign same value to variable in reference.</li> </ul>"},{"location":"Languages%26Tools/Docker/reading/","title":"Reading","text":"<ul> <li>Learn Docker: Container training</li> </ul>"},{"location":"Languages%26Tools/Docker/reading/#tools","title":"Tools","text":"<ul> <li>dive</li> </ul>"},{"location":"Languages%26Tools/Docker/reading/#docker-history-of-layers","title":"Docker history of layers","text":"<pre><code>docker history --human --format \"{{.CreatedBy}}: {{.Size}}\" &lt;container name&gt;\n</code></pre>"},{"location":"Languages%26Tools/Golang/decode%20json%20with%20proper%20types/","title":"Decode json with proper types","text":"<p>I had to unmarshall a <code>POST</code> body JSON payload into a <code>struct</code> but the payload had all fields as <code>string</code> and I wanted to have proper data types for the keys.</p> <p>This is how the <code>payload</code> looked like:</p> <pre><code>{\n\"bufsize\": \"512\",\n\"class\": \"IN\",\n\"do\": \"false\",\n\"duration\": \"0.000072844\",\n\"id\": \"33531\",\n\"level\": \"INFO\",\n\"name\": \"mrkaran.dev.\",\n\"proto\": \"udp\",\n\"rcode\": \"NOERROR\",\n\"rflags\": \"qr,aa,rd,ra\",\n\"rsize\": \"83\",\n\"server_addr\": \"127.0.0.1\",\n\"server_port\": \"53256\",\n\"size\": \"29\",\n\"type\": \"A\"\n}\n</code></pre> <p>Some of the fields like <code>bufsize</code>, <code>size</code>, <code>id</code> should be of type <code>int32</code>. To decode these <code>string</code> fields into the types defined in struct, we can use <code>json:\",string\"</code>.</p> <p>This is how the <code>struct</code> looks:</p> <pre><code>type Log struct {\nBufSize    int     `json:\"bufsize,string\"`\nClass      string  `json:\"class\"`\nDO         bool    `json:\"do,string\"`\nDuration   float64 `json:\"duration,string\"`\nID         int     `json:\"id,string\"`\nLevel      string  `json:\"level\"`\nName       string  `json:\"name\"`\nProto      string  `json:\"proto\"`\nRCode      string  `json:\"rcode\"`\nRFlags     string  `json:\"rflags\"`\nRSize      int     `json:\"rsize,string\"`\nServerAddr string  `json:\"server_addr\"`\nSererPort  int     `json:\"server_port,string\"`\nSize       int     `json:\"size,string\"`\nType       string  `json:\"type\"`\n}\n</code></pre> <p>Quoting from the docs:</p> <p>The \"string\" option signals that a field is stored as JSON inside a JSON-encoded string. It applies only to fields of string, floating point, integer, or boolean types. This extra level of encoding is sometimes used when communicating with JavaScript programs:</p>"},{"location":"Languages%26Tools/Golang/gotcha/","title":"Gotcha","text":""},{"location":"Languages%26Tools/Golang/gotcha/#http-responses","title":"HTTP Responses","text":"<p>If you've a <code>http.ResponseWriter</code> object and using it to directly write the response to the connection, the order in which you write different parts of response is very important:</p> <pre><code>// First write headers.\nwr.Header().Set(\"Content-Type\", \"text/plain; version=0.0.4\")\n// Then set the status code. And yes, this is the function name for setting status code!\nwr.WriteHeader(http.StatusOK)\n// Then finally write the response body.\nwr.Write([]byte(\"hello world\"))\n</code></pre> <p>[!note] - Headers should be written first. If any extra header is set after calling <code>WriteHeader</code> it's a no-op. - Body should be after <code>WriteHeader</code>. Else it's a no-op.</p>"},{"location":"Languages%26Tools/Golang/reading/","title":"Reading","text":"<ul> <li>https://www.youtube.com/watch?v=7QDVRowyUQA</li> <li>https://www.youtube.com/watch?v=2KmHtgtEZ1s</li> <li>https://research.swtch.com/gotour https://github.com/golang/go/wiki/GoTalks https://github.com/alco/gostart https://golangexample.com/a-practical-golang-project-layout/ https://github.com/thockin/go-build-template https://peter.bourgon.org/blog/2016/02/07/logging-v-instrumentation.html https://peter.bourgon.org/ok-log/</li> </ul> <p>https://peter.bourgon.org/blog/2017/06/09/theory-of-modern-go.html</p> <p>https://peter.bourgon.org/go-best-practices-2016/#top-tip-9</p> <p>https://medium.com/@benbjohnson/standard-package-layout-7cdbc8391fc1#.ds38va3pp</p> <p>https://www.youtube.com/watch?v=spKM5CyBwJA</p> <p>https://www.crunchydata.com/developers/playground/btree-indexes</p> <p>https://postgrespro.com/community/courses/2dINTRO</p> <ul> <li> <p>Use of &amp; and * in Golang</p> </li> <li> <p>Tutorial</p> </li> </ul>"},{"location":"Languages%26Tools/Golang/reading/#concurrency-patterns","title":"Concurrency Patterns","text":""},{"location":"Languages%26Tools/Golang/reading/#videos","title":"Videos","text":"<ul> <li>https://www.youtube.com/watch?v=QDDwwePbDtw</li> <li>https://medium.com/airasia-com-tech-blog/goroutines-waitgroups-writing-concurrent-programs-in-golang-888a1bb90053</li> </ul>"},{"location":"Languages%26Tools/Golang/reading/#slides","title":"Slides","text":"<ul> <li>https://talks.golang.org/2012/concurrency.slide#19</li> <li>https://talks.golang.org/2013/advconc.slide#5</li> </ul>"},{"location":"Linux/Command%20Line/","title":"Command Line","text":""},{"location":"Linux/Command%20Line/#tty","title":"TTY","text":"<ul> <li>http://www.linusakesson.net/programming/tty/<ul> <li>Exploring more on how tty works.</li> </ul> </li> </ul>"},{"location":"Linux/Command%20Line/#cli-functions","title":"Cli Functions","text":""},{"location":"Linux/Command%20Line/#generate-password","title":"Generate Password","text":"<pre><code>function gen_pass() {\nlength=${1:?\"length must be specified\"}\nlength=$((length/2))\n\ndd if=/dev/random bs=1 count=${length} 2&gt;/dev/null | od -An -tx1 | tr -d ' \\t\\n' ; echo\n}\n</code></pre>"},{"location":"Linux/Command%20Line/#matrix-like-output-in-shell","title":"Matrix like output in shell","text":"<pre><code>matrix() {\necho -e \"\\e[1;40m\" ; clear ; while :; do echo $LINES $COLUMNS $(( $RANDOM % $COLUMNS)) $(( $RANDOM % 72 )) ;sleep 0.05; done | awk '{ letters=\"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789@#$%^&amp;*()\"; c=$4;        letter=substr(letters,c,1);a[$3]=0;for (x in a) {o=a[x];a[x]=a[x]+1; printf \"\\033[%s;%sH\\033[2;32m%s\",o,x,letter; printf \"\\033[%s;%sH\\033[1;37m%s\\033[0;0H\",a[x],x,letter;if (a[x] &gt;= $1) { a[x]=0; } }}'\n}\n</code></pre>"},{"location":"Linux/Desktop%20Managers/","title":"Desktop Managers","text":""},{"location":"Linux/Desktop%20Managers/#screen-share-in-wayland-dm","title":"Screen share in Wayland DM","text":"<p>While screen sharing in wayland window manager, the window gets shared accurately but with full screen share it's just the cursor with black screen. I while using my arch linux, encountered this, and the only solution found on browsers was to <code>enable</code> this flag <code>#enable-webrtc-pipewire-capturer</code>.</p>"},{"location":"Linux/Desktop%20Managers/#on-edge","title":"On edge","text":"<ul> <li>Go to <code>edge://flags/#enable-webrtc-pipewire-capturer</code> and enable it.</li> </ul>"},{"location":"Linux/Desktop%20Managers/#on-chrome","title":"On chrome","text":"<ul> <li>Go to <code>chrome://flags/#enable-webrtc-pipewire-capturer</code> and enable it.</li> </ul>"},{"location":"Linux/Nginx/","title":"Nginx","text":""},{"location":"Linux/Nginx/#setup-nginx-in-a-ubuntu-server","title":"Setup Nginx in a ubuntu server","text":"<pre><code>sudo apt-get update\nsudo apt-get install nginx -y\nps auwx | grep nginx\n</code></pre>"},{"location":"Linux/Nginx/#add-a-http-server-to-deployment","title":"Add a http server to deployment","text":"<pre><code>cd /etc/nginx/sites-available\nsudo nano &lt;domain_name eg: imagery.rajivharlalka.me&gt;\n</code></pre> <p>Simple Nginx config of http server</p> <pre><code>server {\nlisten 80;\nlisten [::]:80;\n\nserver_name imagery.rajivharlalka.me;\naccess_log /var/log/nginx/reverse-access.log;\nerror_log /var/log/nginx/reverse-error.log;\n\nlocation / {\nproxy_pass http://127.0.0.1:3000;\n}\n}\n</code></pre> <ul> <li> <p>save and exit</p> </li> <li> <p>create symlink from sites-available to sites-enabled</p> </li> </ul> <pre><code>sudo ln -s /etc/nginx/sites-available/&lt;file-name&gt; /etc/nginx/sites-enabled/&lt;file-name&gt;\n</code></pre> <ul> <li>test nginx config and reload</li> </ul> <pre><code>sudo nginx -t &amp;&amp; sudo nginx -s reload\n</code></pre> <p>if everything ok then server should be start serving</p>"},{"location":"Linux/Nginx/#https-config-through-certbot","title":"HTTPS config through certbot","text":"<ul> <li>PreRequisites:   Add the name as a A name to dns cloud-providers first.</li> </ul> <p>Install certbot</p> <pre><code>sudo apt-get update\nsudo apt-get install certbot\nsudo apt-get install python3-certbot-nginx\n</code></pre> <p>Now Run to create certificates</p> <pre><code>sudo certbot --nginx -d &lt;domain-name&gt;\n</code></pre> <p>This should do everything.</p>"},{"location":"Linux/SSH/","title":"SSH","text":""},{"location":"Linux/SSH/#reading-material","title":"Reading Material","text":""},{"location":"Linux/SSH/#reading","title":"reading","text":""},{"location":"Linux/SSH/#ssh-tunnels","title":"ssh tunnels","text":"<p>https://iximiuz.com/en/posts/ssh-tunnels/</p>"},{"location":"Postgresql/BRIN%20Index/","title":"BRIN Index","text":"<p>Block Range Index</p> <ul> <li>helps in searching over large time series data.</li> <li>takes up significantly less space compared to B+ trees.</li> <li>An entry in BRIN index points to a page and stores two values<ul> <li>page's minimum and maximum value.</li> </ul> </li> <li>BRIN outperforms B+ tree when working on large datasets. [1]</li> </ul> <p>\"handling very large tables in which certain columns have some natural correlation with their physical location within the table\"</p> <ul> <li>extremely low insert costs</li> <li>extremely small index sizes</li> </ul> <p>References: [1] https://www.crunchydata.com/blog/postgresql-brin-indexes-big-data-performance-with-minimal-storage https://www.crunchydata.com/blog/postgres-indexing-when-does-brin-win</p>"},{"location":"Postgresql/Configuration%20guidelines/","title":"Configuration guidelines","text":"<ul> <li> <p>If your database is larger than 128 megabytes (MB), then you'll probably benefit from increasing shared_buffers, the physical cache size</p> </li> <li> <p>If you have a dedicated database server with 1GB or more of RAM, a reasonable starting value for\u00a0<code>shared_buffers</code>\u00a0is 25% of the memory in your system</p> </li> </ul> <p>Shared Buffer Heap Hit Rate <pre><code>select sum(heap_blks_hit)*100/(sum(heap_blks_read)+sum(heap_blks_hit)+1) from pg_statio_all_tables ;\n</code></pre></p> <p>Shared Buffer TOAST hit rate <pre><code>select sum(toast_blks_hit)*100/(sum(toast_blks_read)+sum(toast_blks_hit)+1) from pg_statio_all_tables ;\n</code></pre></p> <p>Index Hit Rate <pre><code>select sum(tidx_blks_hit)*100/(sum(tidx_blks_read)+sum(tidx_blks_hit)+1) from pg_statio_all_tables ;\n</code></pre></p> <p>Unused Indexes <pre><code>select relname||'.'||indexrelname from pg_stat_user_indexes where idx_scan=0 and not exists (select 1 from pg_constraint where conindid=indexrelid) ORDER BY relname, indexrelname\n</code></pre> <pre><code>select relname||'.'||indexrelname from pg_stat_user_indexes where idx_scan=0 ORDER BY relname, indexrelname\n</code></pre></p> <p>Ref: https://github.com/jfcoz/postgresqltuner</p> <ul> <li> <p>If there is heavy write activity, you may want to set wal_buffers to a much higher value than the default. In fact, wal_buffers is automatically set from the value of shared_buffers, following a rule that fits most cases. However, it is always possible to specify an explicit value that overrides the computation for the very few cases where the rule is not good enough.</p> </li> <li> <p>If you're doing heavy write activity and/or large data loads, you may want to set max_wal_size and min_wal_size higher than the default to avoid wasting input/output (I/O) in excessively frequent checkpoints. You may also wish to set checkpoint_timeout an checkpoint_completion_target.</p> </li> </ul>"},{"location":"Postgresql/General%20resources/","title":"General resources","text":"<ul> <li>https://postgresqlco.nf/doc/en/param/enable_indexscan/</li> <li>https://pgpedia.info/p/pg_stat_user_functions.html#:~:text=pg_stat_user_functions%20is%20a%20statistics%20view%20showing%20statistics%20about,tracked%20function.%20pg_stat_user_functions%20was%20added%20in%20PostgreSQL%208.4</li> <li>https://www.influxdata.com/blog/metrics-to-monitor-in-your-postgresql-database/</li> <li>https://dbaclass.com/article/monitor-sql-queries-in-postgres-using-pg_stat_statements/</li> <li>https://www.citusdata.com/blog/2019/02/08/the-most-useful-postgres-extension-pg-stat-statements/</li> <li>https://www.eversql.com/postgresql-pg_stat_statements/</li> </ul>"},{"location":"Postgresql/Important_SQL/","title":"Important SQL","text":"<pre><code>SELECT table_schema ,\nTABLE_NAME ,\nCOLUMN_NAME ,\ndata_type ||coalesce(' ' || text(character_maximum_length), '') ||coalesce(' ' || text(numeric_precision), '') ||coalesce(',' || text(numeric_scale), '') AS data_type\nFROM information_schema.columns\nWHERE COLUMN_NAME IN\n(SELECT COLUMN_NAME\nFROM\n(SELECT COLUMN_NAME ,\ndata_type ,\ncharacter_maximum_length ,\nnumeric_precision ,\nnumeric_scale\nFROM information_schema.columns\nWHERE table_schema NOT IN ('information_schema',\n'pg_  \ncatalog')\nGROUP BY COLUMN_NAME ,\ndata_type ,\ncharacter_maximum_length ,\nnumeric_precision ,\nnumeric_scale) derived\nGROUP BY COLUMN_NAME\nHAVING count(*) &gt; 1)\nAND table_schema NOT IN ('information_schema',\n'pg_catalog')\nORDER BY COLUMN_NAME ;\n</code></pre>"},{"location":"Postgresql/Important_SQL/#find-relation-between-rows-of-table","title":"Find relation between rows of  table","text":"<pre><code>SELECT attname, n_distinct  FROM pg_stats  WHERE schemaname = 'public'  AND tablename = 'ord';\n</code></pre>"},{"location":"Postgresql/Important_SQL/#cache-hit-rate","title":"Cache Hit Rate","text":"<pre><code>SELECT 'cache hit rate' AS name, sum(heap_blks_hit) / (sum(heap_blks_hit) + sum(heap_blks_read)) AS ratio FROM pg_statio_user_tables;\n</code></pre>"},{"location":"Postgresql/PostgreSQL/","title":"PostgreSQL","text":"<ul> <li>Maintenance commands: ANALYZE, VACUUM, VACUUM FULL/CLUSTER </li> <li>Index commands: CREATE INDEX, REINDEX</li> <li>Backup/replication: BASE BACKUP</li> <li>Data load/unload: COPY</li> </ul> <ul> <li>ANALYZE: pg_stat_progress_analyze</li> <li>VACUUM: pg_stat_progress_vacuum</li> <li>VACUUM FULL, CLUSTER: pg_stat_progress_cluster</li> <li>CREATE INDEX,REINDEX: pg_stat_progress_create_index</li> <li>BASE BACKUP: pg_stat_progress_basebackup</li> <li>COPY: pg_stat_progress_copy</li> </ul>"},{"location":"Postgresql/PostgreSQL/#progress-meter","title":"Progress Meter","text":""},{"location":"Postgresql/PostgreSQL/#base_backup","title":"base_backup","text":"<pre><code>SELECT pid, phase,\n100.0*((backup_streamed*1.0)/backup_total) AS \"progress%\"\nFROM pg_stat_progress_basebackup;\n</code></pre>"},{"location":"Postgresql/PostgreSQL/#copy-from-progress-will-be-as-follows","title":"COPY FROM % progress will be as follows:","text":"<pre><code>SELECT (SELECT relname FROM pg_class WHERE oid = relid),\n100.0*((bytes_processed*1.0)/bytes_total) AS \"progress%\"\nFROM pg_stat_progress_copy;\n</code></pre>"},{"location":"Postgresql/PostgreSQL/#copy-to-progress-will-be-as-follows","title":"COPY TO % progress will be as follows:","text":"<pre><code>SELECT relname,\n100.0*((tuples_processed*1.0)/(case reltuples WHEN 0 THEN 10 WHEN -1 THEN 10 ELSE reltuples END)) AS \"progress%\"\nFROM pg_stat_progress_copy JOIN pg_class on oid = relid;\n</code></pre> <p>Killing in-transaction sessions <pre><code>SELECT pg_terminate_backend(pid)\nFROM pg_stat_activity\nWHERE state = 'idle in transaction'\nAND current_timestamp \u2013 state_change &gt; '10 min';\n</code></pre></p>"},{"location":"Postgresql/Query%20Planner/","title":"Query Planner","text":""},{"location":"Postgresql/Query%20Planner/#costs-variables","title":"Costs Variables","text":"<ul> <li>seq_page_cost : 1.0<ul> <li>Sets the planner's estimate of the cost of a disk page fetch that is part of a series of sequential fetches.</li> </ul> </li> <li>random_page_cost: 4.0<ul> <li>Reducing Value almost equal to <code>seq_page_cost</code> would prefer index scans more and increasing the value would make index scans look more expensive.</li> </ul> </li> <li>cpu_tuple_cost: 0.01<ul> <li>planner's estimate of the cost of processing each row during a query.</li> </ul> </li> <li>cpu_index_tuple_cost: 0.005<ul> <li>planner's estimate of cost of processing each index entry during an index scan.</li> </ul> </li> <li>cpu_operator_cost: 0.0025</li> </ul>"},{"location":"Postgresql/Query%20Planner/#explanations-with-various-scenarios","title":"Explanations with various scenarios","text":"<ol> <li>Simple Sorting on Seq Scan</li> </ol> <p>Query Plan:  <pre><code>&gt; EXPLAIN SELECT * from pg_class ORDER BY relfilenode ;\n                            QUERY PLAN\n-------------------------------------------------------------------\n Sort  (cost=35.89..36.92 rows=410 width=265)\n   Sort Key: relfilenode\n   -&gt;  Seq Scan on pg_class  (cost=0.00..18.10 rows=410 width=265)\n(3 rows)\n</code></pre> COST: the value of cost returns us with two values. abc..xyz     <code>abc</code> is the starting cost of returning the first row from the output after performing the process.      <code>xyz</code> is the total cost of the operation after which all the rows planned would be returned.</p> <p>Estimated total cost is done using: <code>(disk pages read * seq_page_cost) + (rows scanned * cpu_tuple_cost)</code>  ROWS: The number of rows the planner thinks that would be returned. All calculations are made based on this value. WIDTH: PostgreSQL's idea about the number of bytes one row of the returned value would contain.</p>"},{"location":"Postgresql/Query%20Planner/#disable-different-query-planners","title":"Disable Different Query Planners","text":"<ul> <li>SET enable_indexscan = TRUE/FALSE</li> <li>SET enable_bitmapscan = TRUE/FALSE;</li> </ul>"},{"location":"Postgresql/Query%20Planner/#list-all-query-planners","title":"List all query planners","text":"<pre><code>SELECT name, setting, short_desc || COALESCE(E'\\n' || extra_desc, '')\nFROM pg_settings WHERE name ~ '^enable_';\n</code></pre> <p>Ref:  1. https://www.depesz.com/2013/04/16/explaining-the-unexplainable/ 2. </p>"},{"location":"Postgresql/Types%20of%20Indexes/","title":"Types of Indexes","text":""},{"location":"Postgresql/Types%20of%20Indexes/#b-tree-index","title":"B+ Tree Index","text":""},{"location":"Postgresql/Types%20of%20Indexes/#brin-index","title":"BRIN Index","text":""},{"location":"Postgresql/Users%20and%20Security/","title":"Users and Security","text":"<p>Docs links: https://www.postgresql.org/docs/current/user-manag.html https://www.postgresql.org/docs/current/sql-alterrole.html</p>"},{"location":"Postgresql/Using%20Docker/","title":"Using Docker","text":""},{"location":"Postgresql/Using%20Docker/#setup-postgres-locally-using-docker","title":"Setup postgres locally using docker","text":"<pre><code>docker run --name postgresql-container -p 5432:5432 -e POSTGRES_PASSWORD=test-db -d postgres\n</code></pre>"},{"location":"Postgresql/Using%20Docker/#docker-compose","title":"Docker-compose","text":"<pre><code>version: '3'\n\nservices:\n  postgres:\n    container_name: postgres\n    image: postgres:latest\n    volumes:\n      - dbdata:/var/lib/postgresql/data\n    ports:\n      - 5432:5432\n    environment:\n      POSTGRES_USER: \"root\"\nPOSTGRES_PASSWORD: \"password\"\nrestart: always\n\nvolumes:\n  dbdata:\n</code></pre>"},{"location":"Postgresql/WAL/","title":"WAL","text":""},{"location":"Postgresql/WAL/#wal_level","title":"wal_level","text":"<ul> <li>determines how much information is written to the WAL<ul> <li>replica<ul> <li>which writes enough data to support WAL archiving and replication, including running read-only queries on a standby server</li> </ul> </li> <li>minimal<ul> <li>emoves all logging except the information required to recover from a crash or immediate shutdown.</li> </ul> </li> <li>logical <ul> <li>adds information necessary to support logical decoding</li> </ul> </li> </ul> </li> </ul>"},{"location":"Postgresql/functions/","title":"Functions","text":"<ol> <li><code>repeat(text,number)</code> - repeats the text number times.</li> <li>eg: repeat('hello',4) -&gt; hellohellohellohello</li> <li><code>num_nulls(arguments)</code> and <code>num_nonnulls(arguments)</code> -&gt; returns the number of nulls and non-null characters in the list of arguments.</li> <li>eg: num_nonnulls(1,2,3,NULL) -&gt; 3</li> <li>Date Time formatting template patterns</li> <li><code>overlaps</code> - returns if two intervl of time overlaps or not.</li> <li>eg: (start1, end1) OVERLAPS (start2, end2)      (start1, length1) OVERLAPS (start2, length2)      SELECT (DATE '2001-02-16', DATE '2001-12-21') OVERLAPS      (DATE '2001-10-30', DATE '2002-10-30');      Result: true</li> <li><code>gen_random_uuid()</code> -&gt; generates a random uuid version 4</li> </ol>"},{"location":"Postgresql/reading/","title":"reading","text":"<ul> <li>Database Migrations</li> <li>Postgres incident Report</li> </ul>"},{"location":"Postgresql/Conferences/Additional%20IO%20Observability%20in%20Postgres%20with%20pg_stat_io/","title":"Additional IO Observability in Postgres with pg stat io","text":""},{"location":"Postgresql/Conferences/Additional%20IO%20Observability%20in%20Postgres%20with%20pg_stat_io/#short-forms","title":"Short-forms:","text":"<ul> <li> <p>TPS - Transaction per second.</p> </li> <li> <p>high tps </p> </li> <li>consistent low latency</li> </ul>"},{"location":"Postgresql/Conferences/Additional%20IO%20Observability%20in%20Postgres%20with%20pg_stat_io/#common-io-performance-issues","title":"Common IO performance Issues","text":"<p>Due to wrongly configured <code>share_buffers</code> which causes high io.</p> <p>tuning autovacuum is difficult and mostly changes for every workload. Need to look into autovacuum frequency.</p>"},{"location":"Postgresql/Conferences/Additional%20IO%20Observability%20in%20Postgres%20with%20pg_stat_io/#postgresql-io-tuning-targets","title":"PostgreSQL I/O Tuning Targets","text":"<ul> <li>shared_bufers</li> <li>background writer</li> <li>checkpointer</li> <li>autovacuum</li> </ul>"},{"location":"Postgresql/Conferences/Additional%20IO%20Observability%20in%20Postgres%20with%20pg_stat_io/#io-statistics-views","title":"I/O statistics views","text":"<ul> <li>pg_stat_database</li> <li>pg_statio_all_tables</li> <li>pg_stat_bgwriter</li> <li>pg_stat_statements</li> </ul> <p>pg_stat_io in PG 16</p>"},{"location":"Postgresql/Conferences/Additional%20IO%20Observability%20in%20Postgres%20with%20pg_stat_io/#data-driven-tuning-with-pg_stat_io","title":"Data driven tuning with pg_stat_io","text":"<ul> <li>data might not always fit in shared_buffers  </li> </ul> <p>client-backend normal relation write is high which is not is needed. This write is not related to insert/update write but a client looking for shared buffers it can find a buffer and it has to flush the data thats in buffer. This technically should be zero and instead background writer and checkpointer to take up this workload.</p> <p>probable sol: decrease background delay and increase background_writer_max_lru_pages (Background writer tuning)</p> <p></p> <ul> <li>shared buffers is too small.</li> <li>theres almost write for every read: bad</li> <li>most likely evicting and reading from the same blocks over and over again.</li> <li>signal to increase shared_buffers</li> </ul> <p>Cache Hit ration query <pre><code>SELECT (hits/(reads+hits)::float) *100 FROM pg_stat_io\nWHERE\nbackend_type ='client backend' AND\nio_object = 'relation' AND\nio_context = 'normal';\n</code></pre></p> <p> - avoid premature io  No need to increase shared-buffers here as actual cache-hit ratio is large-enough to handle it.</p>"},{"location":"Postgresql/postgres.fm/Row%20Estimates/","title":"Row Estimates","text":"<ul> <li>hash joins, merge joins</li> <li>nested loops are good where the relation(no of rows) on one side is smaller. </li> <li>check : analyse the table, collect statistics again.</li> <li>we can analyse a single column</li> <li>also happens as a part of auto vacuum</li> <li>auto vacuum has three task: <ul> <li>vacuuming</li> <li>prevent transaction from freezing</li> <li>auto analyzing</li> <li>maintaining free space map and visibility map</li> </ul> </li> <li>explain analyze and vacuum analyze are completely different</li> <li>explain only doesn't help us to learn anything actually</li> <li>Only Explain helps us to know how planner thinks about the data</li> <li>we can check when analyze ran<ul> <li>all log entries should be there</li> <li>pg_stat_user_tables</li> </ul> </li> <li>default_statistics_target -&gt; increases show significant higher disk io</li> <li>systematic approach - analyse depends on table size and no, of packets to analyse</li> </ul>"},{"location":"Postgresql/postgres.fm/Row%20Estimates/#holistic-approach","title":"holistic approach","text":"<ul> <li>if we increase no. of buckets the queries should not slow down.</li> <li>any other parts of workload which struggle from our change and ensure that we changed something then other parts atleast remain the same.</li> <li>query plans is where the mis-estimate happen.</li> </ul>"},{"location":"Postgresql/postgres.fm/Row%20Estimates/#more-relevant-links","title":"More relevant links","text":"<ul> <li>ANALYZE (docs) https://www.postgresql.org/docs/curre...</li> <li>Autovacuum config (docs) https://www.postgresql.org/docs/curre... </li> <li>Statistics used by the planner (docs) https://www.postgresql.org/docs/curre... </li> <li>CREATE STATISTICS (docs) https://www.postgresql.org/docs/curre... </li> <li>Row count estimates (pgMustard blog post) https://www.pgmustard.com/blog/2018/1... </li> <li>pg_hint_plan https://github.com/ossc-db/pg_hint_plan</li> <li>Optimizer methodology (talk by Robert Haas) \u00a0\u00a0\u00a0PostgreSQL\u00a0Optimi... </li> <li>Tom\u00e1\u0161 Vondra on statistics and hints (an excellent interview we forgot to mention, sorry!) \u00a0\u00a0\u00a0\u00a0\u2022\u00a0s01e06\u00a0Tom\u00e1\u0161\u00a0Vondra</li> </ul>"},{"location":"Projects/Countty/","title":"Countty","text":"<p>A simple analytics tool that counts people visited and provides a simple dashboard for the same. </p> <p>Can be privacy friendly and allow collection of statistics and analyzing via various metrics.</p>"},{"location":"Projects/Dotfiles/","title":"Dotfiles","text":"<p>Some references to dotfiles website which I found interesting to look at.</p> <ul> <li>https://jogendra.dev/i-do-dotfiles</li> <li>https://github.com/jogendra/dotfiles</li> <li>https://github.com/thoughtbot/dotfiles</li> <li>https://github.com/darrylabbate/dotfiles/blob/master/git/.gitignore_global</li> <li>https://github.com/aeolyus/dotfiles/blob/master/ssh/.config/systemd/user/ssh-agent.service</li> <li>https://github.com/xero/dotfiles/blob/master/compton/.config/compton.conf</li> <li>https://github.com/dotphiles/dotphiles</li> <li>https://opensource.com/article/18/9/shell-dotfile</li> <li>https://github.com/webpro/dotfiles/blob/main/runcom/.inputrc</li> </ul>"},{"location":"Random/Fonts/","title":"Fonts","text":"<p>Some fonts I liked along with their references. - \"EB Garamond\", serif</p>"},{"location":"Random/Fonts/#properties-of-fonts","title":"Properties of fonts","text":"<ul> <li>x-height - A better x-height is better for long time reading.</li> <li>weight - defines thickness of characters.</li> </ul>"},{"location":"Random/Monitor%20Search/","title":"Monitor Search","text":""},{"location":"Random/Monitor%20Search/#preferences","title":"Preferences","text":"<ul> <li>24\" display</li> <li>height adjustment stand and swivel rotation</li> <li>audio out jack.</li> </ul> <p>Options - https://amzn.eu/d/ffWGTUV - https://www.amazon.in/Samsung-inch-60-1-Computer-Monitor/dp/B08GC8P3YZ/ref=sr_1_13?crid=3NJOXJWPRASMX&amp;keywords=monitors&amp;qid=1683735400&amp;refinements=p_n_feature_twenty_browse-bin%3A65677820031&amp;rnid=65677809031&amp;s=computers&amp;sprefix=monitors%2Caps%2C253&amp;sr=1-13</p>"},{"location":"Random/Second%20Brain/","title":"Second Brain","text":"<ul> <li>https://wiki.nikiv.dev/</li> <li>https://github.com/sywxio/brain</li> </ul>"},{"location":"Random/DSA/Algorithms/","title":"Algorithms","text":"<ul> <li>Graphs</li> <li>Kadane's Algorithm</li> <li></li> </ul>"},{"location":"Random/DSA/Bellman%20Ford/","title":"Bellman Ford","text":"<ul> <li>change occurs when relaxing edges.</li> <li>Relax all Edges |V| - 1 times</li> <li>Time Complexity, O(V.E)</li> </ul>"},{"location":"Random/DSA/Dijkstra%27s%20Algo/","title":"Dijkstra's Algo","text":"<ul> <li>SSSP problems.</li> <li>find closest node reachable and then relax other node.</li> <li>use priority queue to handle </li> <li>if total loop has negetive weightm then dijkstra fails.</li> </ul>"},{"location":"Random/DSA/Dijkstra%27s%20Algo/#problem","title":"Problem","text":"<ul> <li>City</li> <li>V nodes, E Edges</li> <li>There is a start node S, and there is a truck with c amount of fuel. </li> <li>Each road has a length l and to traverse the road l fuel is needed.</li> <li>There are some fuel tanks in the city and a price <code>P[i]</code> needs to be paid</li> <li>Min cost path.</li> </ul> <p>2. - Graph with weight on edges. - </p>"},{"location":"Random/DSA/Graphs/","title":"Graphs","text":""},{"location":"Random/DSA/Graphs/#bfs","title":"BFS","text":"<p>Time Complexity - O(N.M) - Multi-path Problems     - multiple monsters chasing paths.     - Solve it in O(NM).     - Create A Esuper and do bfs for all start nodes - In Code, whnever pushing to queue, mark the node visited.</p>"},{"location":"Random/DSA/Graphs/#topological-ordering","title":"Topological Ordering","text":"<ul> <li>Property of DAG's</li> <li>prefer BFS (Kahn's Algo)</li> </ul> <p>If want a lexicographically smallest topo array     - use a priority_queue instead of a queue.     - insert negetive of the value of node.     - when popping take the negetive again.</p>"},{"location":"Random/DSA/Graphs/#shortest-path","title":"Shortest path","text":"<p> 1. Finding distance between nodes with some a cost to move between same value and b value between adjancent values.</p> <p> 2. Given a String , in how many bit flips can be reach end string such that we do not encounter any of the banned string in the path.</p>"},{"location":"Random/DSA/Graphs/#overview","title":"Overview","text":"<ul> <li>unweighted<ul> <li>BFS(1) - Single Source shortest path. <pre><code>q.push(st);\ndis[inf];\nwhile(!q.empty())\n{\nx= q.front();\nq.pop();\nfor(auto x: g[x]){\nif(dist[v]&gt;dis[x]+1)\ndis[v]=dis[x]+1;\nq.push(v);\n}\n}\n</code></pre></li> </ul> </li> </ul>"},{"location":"Random/DSA/Graphs/#o-1-bfs","title":"o-1 BFS","text":"<pre><code>- Use a dequee\n- while pushing, if cost is 0 push front, else push back.\n</code></pre>"},{"location":"Random/DSA/Graphs/#problems","title":"Problems","text":"<ol> <li> <p> Min No, of Bridges to build so that all components are connected. </p> </li> <li> <p>Dijkstra's Algo</p> <ul> <li>-ve cycle exists - Galat ans.</li> <li>-ve edge - TLE</li> <li>use a priority queue instead of queue. <pre><code>    if (vis[x]==1) continue;\nvis[x]=1;    </code></pre> after popping from queue, this is necessary to remove redundant node and edges.</li> </ul> </li> <li> <p>Bellman Ford</p> <ul> <li>SSSP in negetive cycles.</li> </ul> </li> </ol>"},{"location":"Random/DSA/Graphs/#all-pair-shortest-path","title":"All Pair Shortest Path","text":"<ul> <li>[[Floyd Warshall's Algorithm]]<ul> <li>Need Adjacency Matrix <pre><code>for k in (1,n)\n    for i in (1,n)\n        for j in (1,n)\n            dist[i][j]= min(dist[i][j],dist[i][k]+dist[k][j])\n</code></pre></li> </ul> </li> </ul>"},{"location":"Random/DSA/Kadane%27s%20Algorithm/","title":"Kadane's Algorithm","text":"<ul> <li>for finding the max sum of contiguous subarray of a given length.</li> <li>Time Complexity - O(n)</li> <li>All numbers should be non-negative.</li> <li>For negative numbers [[Maximum subarray problem algorithm]] should be used. <pre><code>class Solution {\npublic:\nint maxSubArray(vector&lt;int&gt;&amp; nums) {\nint n = nums.size(); // globalSum is where the maximum sum of subarray is stored\n// localSum is where the sum of current subarray is stored\nint globalSum = INT_MIN, localSum = 0;\nfor (int i = 0; i &lt; n; i++) {\n// add current element to current sum \nlocalSum = localSum + nums[i];\n// if current sum is greater than globalSum, update globalSum\nif (globalSum &lt; localSum) {\nglobalSum = localSum;\n}\n// if upon adding ith element current sum is becoming less than 0\n// it cannot contribute to the maximum sum subarray so we neglect it \n// and reset our current sum to 0 to start another subarray freshly\nif (localSum &lt; 0) {\nlocalSum = 0;\n}\n}\nreturn globalSum;\n}\n};\n</code></pre></li> </ul>"},{"location":"Random/DSA/Kahn%27s%20Algo/","title":"Kahn's Algo","text":"<ul> <li>Take nodes with in-degree = 0 and add to topological order.</li> <li>Also helps in checking cycle. <ul> <li>if the length of the topological array is not equal to the length of input points, then a cycle exists.</li> </ul> </li> </ul>"},{"location":"Random/DSA/Trees/","title":"Trees","text":"<ul> <li> <p>simple graph with</p> <ul> <li>n nodes, all pairs connected with n-1 edges</li> <li>only one simple path exists between any pair of nodes.</li> <li>1 connected components, no cycle.</li> </ul> </li> <li> <p>Rooted</p> </li> <li>unrooted</li> </ul>"},{"location":"Random/DSA/Union%20Find/","title":"Union Find","text":"<ul> <li>works on two functions<ul> <li>merge and find</li> </ul> </li> </ul>"},{"location":"Random/DSA/Union%20Find/#minimum-spanning-tree","title":"Minimum Spanning Tree","text":"<ul> <li>Kushkal's Algo <ul> <li>sort edges based on weight</li> <li>if not connected<ul> <li>add that edge</li> </ul> </li> </ul> </li> <li>Prim's Algo</li> </ul>"},{"location":"Readings/urls/The%20TTY%20demystified/","title":"The TTY demystified","text":""},{"location":"Readings/urls/The%20TTY%20demystified/#omnivore","title":"Omnivore","text":"<p>Read on Omnivore Read Original</p>"},{"location":"Readings/urls/University%20of%20Threads%20-%20Product%20Management/","title":"University of Threads &gt; Product Management","text":""},{"location":"Readings/urls/University%20of%20Threads%20-%20Product%20Management/#omnivore","title":"Omnivore","text":"<p>Read on Omnivore Read Original</p>"}]}